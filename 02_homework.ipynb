{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 HW: Introduction to Pytorch\n",
    "\n",
    "As the first step, we need to install a suitable version of pytorch.\n",
    "Go to https://pytorch.org/ and scroll down to the install section.\n",
    "Pick the version fitting for your system and install it.\n",
    "For example, if you do not have a GPU and you run Windows as your operating system:\n",
    "```\n",
    "conda activate idl23\n",
    "conda install pytorch torchvision torchaudio cpuonly -c pytorch\n",
    "```\n",
    "\n",
    "Alternatively, you can use [Google Colab](https://colab.research.google.com/). \n",
    "This is a free service by Google that allows you to run Jupyter notebooks in their cloud. \n",
    "You can get GPU access by changing your runtime in top bar.\n",
    "Their default environment has most standard packages installed, including pytorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Regression\n",
    "\n",
    "Polynomial regression is slight more complex than linear regression.\n",
    "Instead of just modeling the outcome as a linear combination of the features, polynomial regression models the output as a linear combination of polynomials of features.\n",
    "In the case of a single feature, i.e., inputs $x \\in \\R$, the model is defined as:\n",
    "$$f(x,w) = w_0 + w_1 x + w_2 x^2 + w_3 x^3 + \\dots + w_q x^q.$$\n",
    "\n",
    "In the more general case, where $x \\in \\R^p$, the model is defined as:\n",
    "$$f(x,w) = w_0 + w_{11} x_1 + w_{12} x_1^2 + \\dots + w_{1q} x_1^q + w_{21} x_2 + w_{22} x_2^2 + \\dots + w_{2q} x_2^q + \\dots = w_0 + \\sum_{i=1}^p \\sum_{j=1}^q w_{ij} x_i^j.$$\n",
    "\n",
    "In this task, you implement a polynomial regression model in Pytorch and study the effects of the allowed complexity of the model on the quality of the fit to data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import pytorch and matplotlib.pyplot. The second library is commonly imported with the alias plt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T09:36:56.240934900Z",
     "start_time": "2023-11-02T09:36:56.209870600Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell defines synthetic data that your model will have to fit. The ground truth labels will follow a polynomial of degree 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T09:36:56.383446700Z",
     "start_time": "2023-11-02T09:36:56.215877800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.collections.PathCollection at 0x1f39cb44ee0>"
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "n_points = 10\n",
    "\n",
    "def make_targets(x):\n",
    "    return x + 0.5 * x**2 - 0.25 * x**3 + 0.4 * torch.randn_like(x)\n",
    "\n",
    "x = torch.linspace(-2, 3, n_points).reshape(-1, 1)\n",
    "y = make_targets(x)\n",
    "\n",
    "x_val = torch.linspace(-2, 3, 25).reshape(-1, 1) + 0.1 * torch.randn((25, 1))\n",
    "y_val = make_targets(x_val)\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.scatter(x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Implement a one-dimensional polynomial regression model.\n",
    "    1. Create a class `PolyRegression` that inherits from `torch.nn.Module`.\n",
    "    2. Create the `__init__` method. What is necessary to call inside that method for classes that inherit from `Module`? The method should have an integer argument that specifies the degree of the polynomial that will be fitted. The weights can be created with an `nn.Linear` layer, but you can also look at different approaches like using `nn.parameter.Parameter`.\n",
    "    3. Create the forward method. It should implement the first equation of this notebook: $$f(x,w) = w_0 + w_1 x + w_2 x^2 + w_3 x^3 + \\dots + w_q x^q.$$\n",
    "\n",
    "\n",
    "Hint 1: torch.pow can be used to take a value to some power.\n",
    "\n",
    "Hint 2: Pytorch documentation can help you if you are stuck."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T09:36:56.473293Z",
     "start_time": "2023-11-02T09:36:56.386448300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4455],\n",
      "        [-1.9732],\n",
      "        [-5.2707]], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "class PolyRegression(torch.nn.Module):\n",
    "    def __init__(self, degree):\n",
    "        super(PolyRegression, self).__init__()\n",
    "        self.degree = degree\n",
    "        self.weights = torch.nn.Linear(degree + 1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Generate the polynomial features\n",
    "        powers = torch.arange(self.degree + 1, dtype=torch.float32, device=x.device)\n",
    "        x_powers = x ** powers.view(1, -1)\n",
    "\n",
    "        # Compute the polynomial function\n",
    "        y_pred = torch.sum(self.weights(x_powers), dim=1, keepdim=True)\n",
    "        \n",
    "        return y_pred\n",
    "\n",
    "# Create a PolyRegression model with a polynomial degree of 3\n",
    "model = PolyRegression(3)\n",
    "\n",
    "# Generate input data 'x' (assuming 'x' is a tensor with the shape you expect)\n",
    "x = torch.tensor([1.0, 2.0, 3.0]).reshape(-1, 1)\n",
    "\n",
    "# Pass the input data through the model\n",
    "out = model(x)\n",
    "\n",
    "# Print the output\n",
    "print(out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Complete the following function that implements the training loop. It should implement the five general training steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T09:36:56.483789100Z",
     "start_time": "2023-11-02T09:36:56.399478700Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(x, y, model, optimizer, loss_func):\n",
    "    # Set the model in training mode\n",
    "    model.train()\n",
    "    \n",
    "    # Forward pass\n",
    "    predictions = model(x)\n",
    "    \n",
    "    # Calculate the loss\n",
    "    loss = loss_func(predictions, y)\n",
    "    \n",
    "    # Backpropagation\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update model parameters\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()  # Return the current loss as a float\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Complete the following function that implements validation. Use the `torch.no_grad` function decorator or the `torch.no_grad` context manager inside this function to avoid making computations relevant for the gradient computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T09:36:56.483789100Z",
     "start_time": "2023-11-02T09:36:56.416002Z"
    }
   },
   "outputs": [],
   "source": [
    "def eval(x, y, model, loss_func):\n",
    "    # Set the model in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Forward pass\n",
    "    with torch.no_grad():  # Ensure no gradients are computed during evaluation\n",
    "        predictions = model(x)\n",
    "    \n",
    "    # Calculate the loss\n",
    "    loss = loss_func(predictions, y)\n",
    "    \n",
    "    return loss.item()  # Return the current loss as a float\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Combine the above functions to train a polynomial regression model with degree 3. The cell should instantiate a model, optimizer, and loss function, then iterate `n_epochs` many times over data to optimize the model. To ease optimization, use the `torch.optim.Adam` optimizer with `lr=5e-3`. To see whether you are overfitting, you can check the validation loss on `x_val, y_val` from time to time.\n",
    "\n",
    "6. Name three hyperparameters you use in your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T09:36:56.550420800Z",
     "start_time": "2023-11-02T09:36:56.431618300Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (10) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[123], line 24\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n_epochs):\n\u001B[0;32m     22\u001B[0m     \u001B[38;5;66;03m# Training phase\u001B[39;00m\n\u001B[0;32m     23\u001B[0m     model\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[1;32m---> 24\u001B[0m     current_loss \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_one_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss_func\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     26\u001B[0m     \u001B[38;5;66;03m# Validation phase (optional, check validation loss from time to time)\u001B[39;00m\n\u001B[0;32m     27\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m (epoch \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m10\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "Cell \u001B[1;32mIn[121], line 9\u001B[0m, in \u001B[0;36mtrain_one_epoch\u001B[1;34m(x, y, model, optimizer, loss_func)\u001B[0m\n\u001B[0;32m      6\u001B[0m predictions \u001B[38;5;241m=\u001B[39m model(x)\n\u001B[0;32m      8\u001B[0m \u001B[38;5;66;03m# Calculate the loss\u001B[39;00m\n\u001B[1;32m----> 9\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[43mloss_func\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpredictions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m# Backpropagation\u001B[39;00m\n\u001B[0;32m     12\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535\u001B[0m, in \u001B[0;36mMSELoss.forward\u001B[1;34m(self, input, target)\u001B[0m\n\u001B[0;32m    534\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor, target: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 535\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmse_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduction\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreduction\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:3328\u001B[0m, in \u001B[0;36mmse_loss\u001B[1;34m(input, target, size_average, reduce, reduction)\u001B[0m\n\u001B[0;32m   3325\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m size_average \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m reduce \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   3326\u001B[0m     reduction \u001B[38;5;241m=\u001B[39m _Reduction\u001B[38;5;241m.\u001B[39mlegacy_get_string(size_average, reduce)\n\u001B[1;32m-> 3328\u001B[0m expanded_input, expanded_target \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbroadcast_tensors\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3329\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39m_nn\u001B[38;5;241m.\u001B[39mmse_loss(expanded_input, expanded_target, _Reduction\u001B[38;5;241m.\u001B[39mget_enum(reduction))\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\functional.py:73\u001B[0m, in \u001B[0;36mbroadcast_tensors\u001B[1;34m(*tensors)\u001B[0m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function(tensors):\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(broadcast_tensors, tensors, \u001B[38;5;241m*\u001B[39mtensors)\n\u001B[1;32m---> 73\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_VF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbroadcast_tensors\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: The size of tensor a (3) must match the size of tensor b (10) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "# Set a fixed random seed for reproducibility\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# Define your training and validation data with the same number of features\n",
    "# Assuming you have defined 'x', 'y', 'x_val', and 'y_val' correctly\n",
    "\n",
    "# Hyperparameters\n",
    "n_epochs = 100\n",
    "learning_rate = 5e-3\n",
    "\n",
    "# Create a PolyRegression model with a polynomial degree of 3\n",
    "model = PolyRegression(3)\n",
    "\n",
    "# Define the loss function (Mean Squared Error)\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "# Define the optimizer (Adam optimizer with a learning rate)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(n_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    current_loss = train_one_epoch(x, y, model, optimizer, loss_func)\n",
    "\n",
    "    # Validation phase (optional, check validation loss from time to time)\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        validation_loss = eval(x_val, y_val, model, loss_func)\n",
    "        print(f\"Epoch [{epoch + 1}/{n_epochs}] - Training Loss: {current_loss:.4f} - Validation Loss: {validation_loss:.4f}\")\n",
    "    else:\n",
    "        print(f\"Epoch [{epoch + 1}/{n_epochs}] - Training Loss: {current_loss:.4f}\")\n",
    "\n",
    "# After training, you can use the trained model for predictions\n",
    "# For example, you can use the model to predict 'y_pred' from 'x' with: y_pred = model(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Visualize the resulting model with the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-02T09:36:56.507826300Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x.view(-1), y.view(-1), color=\"blue\", label=\"Training data\")\n",
    "ax.scatter(x_val.view(-1), y_val.view(-1), color=\"orange\", label=\"Validation data\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    x_plot = torch.linspace(x.min().item(), x.max().item(), 100).view(-1, 1)\n",
    "    pred_plot = model(x_plot)\n",
    "    ax.plot(x_plot, pred_plot, label=\"Model prediction\", color=\"red\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Revisit the model training.\n",
    "    1. Try to train a model with much higher degree of the polynomial. You may need to change the number of epochs and the learning rate of the optimizer. How does the fit compare to the fit of the model with order 3?\n",
    "    2. What happens if you train a model with degree 1 or 2? Are you over or underfitting; why?\n",
    "\n",
    "9. How would you classify this task in the scheme of slide 6 in deck 2?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idl21",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
