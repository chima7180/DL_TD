{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 HW: Introduction to Pytorch\n",
    "\n",
    "As the first step, we need to install a suitable version of pytorch.\n",
    "Go to https://pytorch.org/ and scroll down to the install section.\n",
    "Pick the version fitting for your system and install it.\n",
    "For example, if you do not have a GPU and you run Windows as your operating system:\n",
    "```\n",
    "conda activate idl23\n",
    "conda install pytorch torchvision torchaudio cpuonly -c pytorch\n",
    "```\n",
    "\n",
    "Alternatively, you can use [Google Colab](https://colab.research.google.com/). \n",
    "This is a free service by Google that allows you to run Jupyter notebooks in their cloud. \n",
    "You can get GPU access by changing your runtime in top bar.\n",
    "Their default environment has most standard packages installed, including pytorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Regression\n",
    "\n",
    "Polynomial regression is slight more complex than linear regression.\n",
    "Instead of just modeling the outcome as a linear combination of the features, polynomial regression models the output as a linear combination of polynomials of features.\n",
    "In the case of a single feature, i.e., inputs $x \\in \\R$, the model is defined as:\n",
    "$$f(x,w) = w_0 + w_1 x + w_2 x^2 + w_3 x^3 + \\dots + w_q x^q.$$\n",
    "\n",
    "In the more general case, where $x \\in \\R^p$, the model is defined as:\n",
    "$$f(x,w) = w_0 + w_{11} x_1 + w_{12} x_1^2 + \\dots + w_{1q} x_1^q + w_{21} x_2 + w_{22} x_2^2 + \\dots + w_{2q} x_2^q + \\dots = w_0 + \\sum_{i=1}^p \\sum_{j=1}^q w_{ij} x_i^j.$$\n",
    "\n",
    "In this task, you implement a polynomial regression model in Pytorch and study the effects of the allowed complexity of the model on the quality of the fit to data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import pytorch and matplotlib.pyplot. The second library is commonly imported with the alias plt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T14:00:20.455210Z",
     "start_time": "2023-11-01T14:00:19.811427200Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pytorch'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpytorch\u001B[39;00m \n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'pytorch'"
     ]
    }
   ],
   "source": [
    "import pytorch \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell defines synthetic data that your model will have to fit. The ground truth labels will follow a polynomial of degree 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T14:00:20.455210Z",
     "start_time": "2023-11-01T14:00:20.455210Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "n_points = 10\n",
    "\n",
    "def make_targets(x):\n",
    "    return x + 0.5 * x**2 - 0.25 * x**3 + 0.4 * torch.randn_like(x)\n",
    "\n",
    "x = torch.linspace(-2, 3, n_points).reshape(-1, 1)\n",
    "y = make_targets(x)\n",
    "\n",
    "x_val = torch.linspace(-2, 3, 25).reshape(-1, 1) + 0.1 * torch.randn((25, 1))\n",
    "y_val = make_targets(x_val)\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.scatter(x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Implement a one-dimensional polynomial regression model.\n",
    "    1. Create a class `PolyRegression` that inherits from `torch.nn.Module`.\n",
    "    2. Create the `__init__` method. What is necessary to call inside that method for classes that inherit from `Module`? The method should have an integer argument that specifies the degree of the polynomial that will be fitted. The weights can be created with an `nn.Linear` layer, but you can also look at different approaches like using `nn.parameter.Parameter`.\n",
    "    3. Create the forward method. It should implement the first equation of this notebook: $$f(x,w) = w_0 + w_1 x + w_2 x^2 + w_3 x^3 + \\dots + w_q x^q.$$\n",
    "\n",
    "\n",
    "Hint 1: torch.pow can be used to take a value to some power.\n",
    "\n",
    "Hint 2: Pytorch documentation can help you if you are stuck.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-01T14:00:20.463220600Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Test that your models works\n",
    "model = PolyRegression(3)\n",
    "out = model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Complete the following function that implements the training loop. It should implement the five general training steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-01T14:00:20.463220600Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(x, y, model, optimizer, loss_func):\n",
    "    \"\"\"Optimizes parameters of model with one pass over training data\n",
    "\n",
    "    Args:\n",
    "        x (torch.Tensor): inputs\n",
    "        y (torch.Tensor): targets\n",
    "\n",
    "    Returns:\n",
    "        float: current loss\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Complete the following function that implements validation. Use the `torch.no_grad` function decorator or the `torch.no_grad` context manager inside this function to avoid making computations relevant for the gradient computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-01T14:00:20.471220700Z"
    }
   },
   "outputs": [],
   "source": [
    "def eval(x, y, model, loss_func):\n",
    "    \"\"\"Compute loss over validation data\n",
    "\n",
    "    Args:\n",
    "        x (torch.Tensor): inputs\n",
    "        y (torch.Tensor): targets\n",
    "\n",
    "    Returns:\n",
    "        float: current loss\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Combine the above functions to train a polynomial regression model with degree 3. The cell should instantiate a model, optimizer, and loss function, then iterate `n_epochs` many times over data to optimize the model. To ease optimization, use the `torch.optim.Adam` optimizer with `lr=5e-3`. To see whether you are overfitting, you can check the validation loss on `x_val, y_val` from time to time.\n",
    "\n",
    "6. Name three hyperparameters you use in your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-01T14:00:20.471220700Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(123)  # fixes initialization of parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Visualize the resulting model with the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T14:00:20.479228900Z",
     "start_time": "2023-11-01T14:00:20.471220700Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x.view(-1), y.view(-1), color=\"blue\", label=\"Training data\")\n",
    "ax.scatter(x_val.view(-1), y_val.view(-1), color=\"orange\", label=\"Validation data\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    x_plot = torch.linspace(x.min().item(), x.max().item(), 100).view(-1, 1)\n",
    "    pred_plot = model(x_plot)\n",
    "    ax.plot(x_plot, pred_plot, label=\"Model prediction\", color=\"red\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Revisit the model training.\n",
    "    1. Try to train a model with much higher degree of the polynomial. You may need to change the number of epochs and the learning rate of the optimizer. How does the fit compare to the fit of the model with order 3?\n",
    "    2. What happens if you train a model with degree 1 or 2? Are you over or underfitting; why?\n",
    "\n",
    "9. How would you classify this task in the scheme of slide 6 in deck 2?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idl21",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
